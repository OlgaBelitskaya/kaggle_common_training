# -*- coding: utf-8 -*-
"""sklearn-pyr.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HpIXlLna_oE83mqLQfhGi4KyqsPtBB6q

[`Python` Version](https://www.kaggle.com/olgabelitskaya/sklearn-cookbook)
"""

conn<-file("widhtml.R")
writeLines("
vfont_family<-c('Smokum','Akronim','Wallpoet',
                'Orbitron','Ewert','Lobster',
                'Roboto','Miss Fajardose','Monoton')
vfont_size<-c(8,10,12,14,16,18,20,22,24,26,28,30,32)
vfont_color<-c('#ff36ff','#ff3636','#3636ff',
               '#36ffff','#ff9636','#ff3696')

idhtml<-function(string,font_color=vfont_color[6],
                 font_family=vfont_family[2],
                 font_size=vfont_size[11]) {
    randi<-sample(1:9999999,1)
    s<-sapply(34,intToUtf8)
    html_str<-c(
      '<style>@import ',s,'https://fonts.',
      'googleapis.com/css?family=',font_family,
      s,'; #rh1',randi,' {font-family:',font_family,
      '; color:',font_color,'; font-size:',font_size,
      'px; text-shadow:3px 3px 3px #aaa;}</style>',
      '<h1 id=',s,'rh1',randi,s,';>',string,'</h1>')
    str<-paste0(html_str,collapse='')
    IRdisplay::display_html(str)}

ipyhtml<-function(font_color=vfont_color[6],
                 font_family=vfont_family[7],
                 font_size=vfont_size[2]) {
    html_str<-c(
        '<style>span {font-family:',font_family,
        '; color:black; text-shadow:3px 3px 3px #aaa;} ',
        'div.output_area pre{font-family:',
        '; font-size',font_size,'px; color:',
        font_color,';}</style>')
    str<-paste0(html_str,collapse='')
    IRdisplay::display_html(str)}  
",conn)

source('widhtml.R'); ipyhtml()
idhtml('Packages, Helpful Functions, and Styling')

conn<-file("rpy_sklearn.R")
writeLines("
library(reticulate); library(imager)
library(IRdisplay); library(ggplot2)
pl<-c('matplotlib','pandas','sklearn',
      'seaborn','h5py','scikit-image')
for (p in pl) {py_install(p)} 
np<-import('numpy'); pd<-import('pandas')
sl<-import('sklearn'); sm<-import('skimage')
ks<-import('keras'); h5<-import('h5py')
pl<-import('pylab'); sn<-import('seaborn')
slds<-import('sklearn.datasets')
slpp<-import('sklearn.preprocessing')
slim<-import('sklearn.impute')
slfe<-import('sklearn.feature_extraction')
slms<-import('sklearn.model_selection')
slme<-import('sklearn.metrics')
sllm<-import('sklearn.linear_model')
slen<-import('sklearn.ensemble')
slne<-import('sklearn.neighbors')
slcl<-import('sklearn.cluster')
",conn)

source('rpy_sklearn.R')

ip<-function(x) {as.integer(x)}
N<-ip(5000)
ohe<-function(x) {
    x<-array_reshape(x,c(-1,1))
    tohe<-slpp$OneHotEncoder(categories='auto')
    as.matrix(tohe$fit(x)$transform(x)) }
tts<-function(X,y) {
    slms$train_test_split(X,y,test_size=.2,
                          random_state=ip(1))}

idhtml('Data')
idhtml('internal datasets',font_size=24)

conn<-file("load_sklearn_data.R")
writeLines("
boston<-slds$load_boston()
X1<-boston$data; y1<-boston$target
dfboston<-data.frame(boston$data)
colnames(dfboston)<-boston$feature_names
dfboston['MEDV']<-boston$target
ip<-function(x) {as.integer(x)}
fig<-pl$figure(figsize=c(10,5))
ax<-fig$add_subplot('111')
sn$histplot(dfboston['MEDV'],stat='density',ax=ax,
            kde='True',bins=ip(30),
            edgecolor='#ff3696',alpha=.1)
pd$plotting$table(ax,head(dfboston,3),loc='top')
pl$tight_layout()
pl$savefig('rpy_p1.png'); im<-load.image('rpy_p1.png')
options(repr.plot.width=10,repr.plot.height=5)
par(mar=c(0,0,0,0)); plot(im,axes=FALSE)
print('Boston Data =>>>')
print(paste0(c('dim: features -',list(dim(X1)),
               ', target -',list(dim(y1))),
             collapse=' '))
",conn)

source("load_sklearn_data.R")

conn<-file("load_sklearn_data2.R")
writeLines("
digits<-slds$load_digits()
X2<-digits$data; y2<-digits$target
print('Digit Data =>>>')
print(paste0(c('dim: features -',list(dim(X2)),
               ', target -',list(dim(y2))),
             collapse=' '))
par(mar=c(0,0,0,0)); n<-sample(dim(X2)[1],1)
im<-array_reshape(X2[n,]/max(X2),c(8,8))
options(repr.plot.width=3,repr.plot.height=3)
plot(as.raster(im))
",conn)

source("load_sklearn_data2.R")

idhtml('artificial datasets',font_size=24)

conn<-file("create_sklearn_data.R")
writeLines("
ip<-function(x) {as.integer(x)}
N<-ip(5000)

# 5000x5 matrix with 5 features (4 responsible for targets), 
# 1 target, 0.97 - the bias factor
artreg<-slds$make_regression(N,ip(5),ip(4),ip(1),.97)
nX3<-np$array(artreg[1]); ny3<-np$array(artreg[2])
X3<-array_reshape(nX3,c(N,5)); y3<-array_reshape(ny3,N)
options(repr.plot.width=10,repr.plot.height=5)
matplot(y3[1:500],X3[1:500,1:5],type='p')
print('Make Regression =>>>')
print(paste0(c('dim: features -',list(dim(X3)),
               ', target -',list(dim(y3))),
             collapse=' '))

ce<-array_reshape(c(1,1,-1,-1,1,-1,-1,1),c(4,2))
artclu<-slds$make_blobs(n_samples=N,cluster_std=.5,centers=ce)
nX4<-np$array(artclu[1]); ny4<-np$array(artclu[2])
X4<-array_reshape(nX4,c(N,2)); y4<-array_reshape(ny4,N)
pl$figure(figsize=c(10,5))
pl$scatter(X4[,1],X4[,2],c=y4,s=3,
           cmap=pl$cm$tab10)
pl$scatter(c(1,-1,1,-1),c(1,-1,-1,1),
           c='black',marker='*',s=150)
pl$savefig('rpy_p1.png'); im<-load.image('rpy_p1.png')
options(repr.plot.width=10,repr.plot.height=5)
par(mar=c(0,0,0,0)); plot(im,axes=FALSE)
print('Make Blobs =>>>')
print(paste0(c('dim: features -',list(dim(X4)),
               ', target -',list(dim(y4))),
             collapse=' '))

artmlc<-slds$make_multilabel_classification(n_classes=ip(3),
                                            n_samples=N,
                                            n_features=ip(2))
nX5<-np$array(artmlc[[1]]); ny5<-np$array(artmlc[[2]])
X5<-array_reshape(nX5,c(N,2)); y5<-array_reshape(ny5,c(N,3))
m=c('o','v','*'); a=c(.2,.5,1); s=c(500,300,100)
pl$figure(figsize=c(10,5))
for (i in 1:3) {
    pl$scatter(X5[1:50,1],X5[1:50,2],c=y5[1:50,i],s=s[i],
               marker=m[i],alpha=a[i],cmap=pl$cm$bwr)}
pl$savefig('rpy_p1.png'); im<-load.image('rpy_p1.png')
options(repr.plot.width=10,repr.plot.height=5)
par(mar=c(0,0,0,0)); plot(im,axes=FALSE)
print('Make Multilabel Classification =>>>')
print(paste0(c('dim: features -',list(dim(X5)),
               ', target -',list(dim(y5))),
             collapse=' '))
",conn)

source("create_sklearn_data.R")

idhtml('external datasets',font_size=24)

conn<-file("load_external_data.R")
writeLines("
mnist<-ks$datasets$mnist$load_data()
train6<-mnist[[1]]; test6<-mnist[[2]]
X_train6<-array_reshape(np$array(train6[[1]]),c(60000,784))
X_train6<-X_train6/max(X_train6)
y_train6<-np$array(train6[[2]])
X_test6<-array_reshape(np$array(test6[[1]]),c(10000,784))
X_test6<-X_test6/max(X_test6)
y_test6<-np$array(test6[[2]])
im<-array_reshape(X_train6[n,],c(28,28))
options(repr.plot.width=3,repr.plot.height=3)
par(mar=c(0,0,0,0)); plot(as.raster(im))
print('MNIST Keras =>>>')
print(paste0(c(
    'train features -',list(dim(X_train6)),
    ', train target -',list(dim(y_train6))),
    collapse=' '))
print(paste0(c('test features -',list(dim(X_test6)),
    ', test target -',list(dim(y_test6))),
    collapse=' '))

fpath<-'../input/classification-of-handwritten-letters/'
fname<-'LetterColorImages_123.h5'
f<-h5$File(paste0(fpath,fname),'r')
keys<-list(f$keys())
letters<-'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'
X7<-array_reshape(np$array(f['images'])/255,c(-1,32*32*3))
y7<-np$array(f['labels'])
im<-array_reshape(X7[n,],c(32,32,3))
options(repr.plot.width=3,repr.plot.height=3)
par(mar=c(0,0,0,0)); plot(as.raster(im))
print('Letters Kaggle =>>>')
print(paste0(c('keys: ',keys)))
print(paste0(
    c('dim: features -',list(dim(X7)),
      ', target -',list(dim(y7))),
    collapse=' '))
print(substring(letters,y7[n],y7[n]))
",conn)

source("load_external_data.R")

idhtml('Extraction and Preprocessing')

conn<-file("dataframe_from_vector.R")
writeLines("
arr1<-c('Hanoi','Frankfurt','Houston',
        'Riyadh','Barcelona','Ankara')
arr2<-c(33,16,28,38,17,27)
tmp<-pd$DataFrame(
    np$nan,index=1:6,columns=c('city','temperature'))
tmp$city<-arr1; tmp$temperature<-as.integer(arr2)
tmp2<-data.frame(cbind(arr1,arr2))
colnames(tmp2)<-c('city','temperature')
tmp2<-transform(
    tmp2,city=as.character(city),
    temperature=as.integer(as.character(temperature)))
options(repr.plot.width=10,repr.plot.height=5)
p<-ggplot(tmp,aes(x=city,y=temperature,
                  color=as.character(temperature)))+
    scale_color_brewer(palette='Reds',name='°C')+
    geom_point(size=5)+theme_bw()
cat(str(tmp)); cat(str(tmp2)); print(p)
",conn)

source("dataframe_from_vector.R")

conn<-file("sklearn_vectorizer.R")
writeLines("
corpus=c('Have you already set your goals for the New Year?',
         paste0('Do you want to lose ten kilos, ',
                'run a marathon or speak fluent English?'), 
         'Some experts believe that you need systems, not goals.',
         'A system is something you do on a regular basis.',
         paste0('This means focusing on what you can control ',
                '(your actions) rather than what you can’t.'),
         'For example, do not focus on losing ten kilos.',
         paste0('Focus on shopping for healthy food and ',
                'cooking something light every day.'),
         'Do not focus on the marathon.',
         'Focus on the training schedule.',
         paste0('Invent a system to improve your English, ',
                'one step at a time.'),
         'Good luck!')
cv<-slfe$text$CountVectorizer(max_df=100)
corpus_features<-cv$fit_transform(
    np$array(corpus,dtype='object'))
options(repr.plot.width=10,repr.plot.height=7)
for (i in 1:11){
    matplot(corpus_features[i,]+3*(i-1),
            xlab='',ylab='',pch='*',ylim=c(0,33),col=i,
            main='The Words` Occurrence in Sentences'); 
    par(new=TRUE)}
ca<-cv$build_analyzer(); print(ca(corpus[1]))
",conn)

source("sklearn_vectorizer.R")

conn<-file("sklearn_imputer.R")
writeLines("
X<-np$random$randn(ip(100))
ch<-np$random$choice(ip(100),ip(20))
X[ch]<-np$nan
X<-np$reshape(X,c(ip(100),ip(1)))
mean_imp<-slim$SimpleImputer(strategy='mean')
median_imp<-slim$SimpleImputer(strategy='median')
dfX<-pd$DataFrame(
    cbind(X,mean_imp$fit(X)$transform(X),
          median_imp$fit(X)$transform(X)))
options(repr.plot.width=10,repr.plot.height=7)
matplot(dfX,type='p',main='Sklearn Simple Imputer')
grid() 
legend(80,2,c('1->X','2->X mean','3->X median'),bty='n')
",conn)

source("sklearn_imputer.R")

m<-sample(1:1700,1)
cy2<-ohe(y2); c(cy2[m,],y2[m])
cy_train6<-ohe(y_train6); c(cy_train6[m,],y_train6[m])
cy_test6<-ohe(y_test6); c(cy_test6[m,],y_test6[m])
cy7<-ohe(y7); c(cy7[m,],y7[m])

X_train1<-tts(X1,y1)[[1]]; X_test1<-tts(X1,y1)[[2]]
y_train1<-tts(X1,y1)[[3]]; y_test1<-tts(X1,y1)[[4]]
c(dim(X_train1),dim(y_train1),dim(X_test1),dim(y_test1))
X_train2<-tts(X2,y2)[[1]]; X_test2<-tts(X2,y2)[[2]]
y_train2<-tts(X2,y2)[[3]]; y_test2<-tts(X2,y2)[[4]]
c(dim(X_train2),dim(y_train2),dim(X_test2),dim(y_test2))
X_train7<-tts(X7,y7)[[1]]; X_test7<-tts(X7,y7)[[2]]
y_train7<-tts(X7,y7)[[3]]; y_test7<-tts(X7,y7)[[4]]
c(dim(X_train7),dim(y_train7),dim(X_test7),dim(y_test7))

idhtml('Classification')

clf<-slne$KNeighborsClassifier()
clf$fit(X_train2,y_train2)    
y_clf_train2<-clf$predict(X_train2)
y_clf_test2<-clf$predict(X_test2)        
acc_clf_train2<-slme$accuracy_score(y_train2,y_clf_train2)
acc_clf_test2<-slme$accuracy_score(y_test2,y_clf_test2)
c(acc_clf_train2,acc_clf_test2)
#y_clf_test2

clf<-slen$GradientBoostingClassifier()
clf$fit(X_train6[1:10000,],y_train6[1:10000])    
y_clf_train6<-clf$predict(X_train6[1:10000,])
y_clf_test6<-clf$predict(X_test6[1:2000,])        
acc_clf_train6<-slme$accuracy_score(y_train6[1:10000],y_clf_train6)
acc_clf_test6<-slme$accuracy_score(y_test6[1:2000],y_clf_test6)
c(acc_clf_train6,acc_clf_test6)

clf<-slen$RandomForestClassifier()
clf$fit(X_train7,y_train7)    
y_clf_train7<-clf$predict(X_train7)
y_clf_test7<-clf$predict(X_test7)        
acc_clf_train7<-slme$accuracy_score(y_train7,y_clf_train7)
acc_clf_test7<-slme$accuracy_score(y_test7,y_clf_test7)
c(acc_clf_train7,acc_clf_test7)

idhtml('Regression')

reg1<-slen$GradientBoostingRegressor()
reg1$fit(X_train1,y_train1)    
y_reg_train11<-reg1$predict(X_train1)
y_reg_test11<-reg1$predict(X_test1)        
r2_reg_train11<-slme$r2_score(y_train1,y_reg_train11)
r2_reg_test11<-slme$r2_score(y_test1,y_reg_test11)
c(r2_reg_train11,r2_reg_test11)
reg2<-slne$KNeighborsRegressor()
reg2$fit(X_train1,y_train1)    
y_reg_train12<-reg2$predict(X_train1)
y_reg_test12<-reg2$predict(X_test1)        
r2_reg_train12<-slme$r2_score(y_train1,y_reg_train12)
r2_reg_test12<-slme$r2_score(y_test1,y_reg_test12)
c(r2_reg_train12,r2_reg_test12)

pl$figure(figsize=c(10,5)); k<-30
pl$scatter(1:k,y_test1[1:k],marker='*',s=100,
           color='black',label='Real data')
pl$plot(1:k,y_reg_test11[1:k],lw=2,label='Gradient Boosting')
pl$plot(1:k,y_reg_test12[1:k],lw=2,label='KNeighbors')
pl$xlabel('Observations'); pl$ylabel('Targets')
pl$title('Regressors. Test Results. Boston')
pl$legend(loc=2,fontsize=10)
pl$savefig('rpy_p1.png'); im<-load.image('rpy_p1.png')
options(repr.plot.width=10,repr.plot.height=5)
par(mar=c(0,0,0,0)); plot(im,axes=F)

idhtml('Interactive Py Practice')
url<-paste0('https://olgabelitskaya.github.io/',
            'sklearn_cookbook_sagecells.html')
html_str<-c('<div style="border:10px double white; ',
    'width:680px; height:630px; overflow:auto; ',
    'padding:5px; background-color:ghostwhite">',
    '<iframe src="',url,
    '" width="650" height="600"/></div>')
html_str<-(paste0(html_str,collapse=''))
IRdisplay::display_html(html_str)