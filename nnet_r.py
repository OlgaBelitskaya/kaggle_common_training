# -*- coding: utf-8 -*-
"""nnet-r.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kWc8kWuli6X5vZcdo3RZGd_RkPjEtbKC

<h1 class='font-effect-3d' style='color:#66FF66; font-family:Akronim;'>Styling, Links, Helpful Functions, & Code Modules</h1>
"""

library(IRdisplay); library(repr)
library(readr); library('MASS')
library(tensorflow); library(keras)
library(nnet); library(caret); library(doParallel)
library(imager); library(R6)
path1<-"../input/digit-recognizer/"
path2<-"../input/boston-housing/"
fw1<-"best.digits.h5"
fw2<-"best.boston.h5"

display_html("<style> 
@import url('https://fonts.googleapis.com/css?family=Akronim|Roboto&effect=3d|fire-animation');
body {background-color:#AAF0D1;} 
span {color:black; text-shadow:4px 4px 4px #aaa;}
div.output_prompt {color:#FF9966;} 
div.input_prompt {color:#66FF66;} 
div.output_area pre,div.output_subarea {font-size:15px; color:#FF9966;}
div.output_stderr pre {background-color:#AAF0D1;} 
</style>")

"""<h1 class='font-effect-3d' style='color:#66FF66; font-family:Akronim;'>Data</h1>"""

digits<-read.csv(paste0(path1,"train.csv"))
n<-nrow(digits)
digits<-digits[sample(n),]
digit_labels<-as.matrix(digits[,1])
fdigit_labels<-as.factor(digits$label)
digit_images<-as.matrix(digits[,-1])/255
c(dim(digit_images),dim(digit_labels))
options(repr.plot.width=2,repr.plot.height=2)
par(mar=c(1,1,1,1)); n<-sample(42000,1)
image_example<-digit_images[n,]
image_example<-array_reshape(image_example,c(28,28))
c(dim(image_example),digit_labels[n])
plot(as.raster(image_example))

train_indices<-1:round(.8*n)
valid_indices<-(round(.8*n)+1):round(.9*n)
test_indices<-(round(.9*n)+1):n
x_train1<-digit_images[train_indices,]
y_train1<-digit_labels[train_indices,]
x_valid1<-digit_images[valid_indices,]
y_valid1<-digit_labels[valid_indices,]
x_test1<-digit_images[test_indices,]
y_test1<-digit_labels[test_indices,]
cy_train1<-class.ind(y_train1)
cy_valid1<-class.ind(y_valid1)
cy_test1<-class.ind(y_test1)
c(dim(x_train1),dim(x_valid1),dim(x_test1),
  dim(cy_train1),dim(cy_valid1),dim(cy_test1))

data(Boston); nb<-dim(Boston)[1]
head(Boston)

boston<-Boston[sample(nb),]
boston_features<-as.matrix(boston[,-14])
boston_targets<-as.matrix(boston[,14])
train_indices<-1:round(.8*nb)
valid_indices<-(round(.8*nb)+1):round(.9*nb)
test_indices<-(round(.9*nb)+1):nb
x_train2<-boston_features[train_indices,]
y_train2<-boston_targets[train_indices,]
x_valid2<-boston_features[valid_indices,]
y_valid2<-boston_targets[valid_indices,]
x_test2<-boston_features[test_indices,]
y_test2<-boston_targets[test_indices,]

"""<h1 class='font-effect-3d' style='color:#66FF66; font-family:Akronim;'>Classification</h1>
nnet & keras
"""

dco<-detectCores() 
clu<-makeCluster(dco)
registerDoParallel(clu)

train_par<-trainControl(method="cv",number=3)
gnn<-expand.grid(.size=c(1,4,8,16),.decay=.1^5)
set.seed(42)
cnnet<-train(digit_images,fdigit_labels,trControl=train_par,
             method="nnet",tuneGrid=gnn,MaxNWts=20000)
cnnet

stopCluster(clu)

cnnks<-keras_model_sequential()
cnnks %>% 
  layer_conv_2d(input_shape=c(28,28,1),
                filter=32,kernel_size=c(5,5),
                padding="same") %>%  
  layer_activation_leaky_relu(alpha=.02) %>%   
  layer_max_pooling_2d(pool_size=c(2,2)) %>%  
  layer_dropout(.25) %>%
  layer_conv_2d(filter=196,kernel_size=c(5,5),
                padding="same") %>% 
  layer_activation_leaky_relu(alpha=.02) %>%  
  layer_max_pooling_2d(strides=c(2,2)) %>%  
  layer_dropout(.25) %>%
  layer_global_max_pooling_2d() %>%  
  layer_dense(1024) %>%  
  layer_activation_leaky_relu(alpha=.02) %>% 
  layer_dropout(.25) %>%    
  layer_dense(10) %>%    
  layer_activation("softmax")
cnnks %>%
  compile(loss="categorical_crossentropy",
          optimizer="nadam",metrics="accuracy")

d<-c(dim(x_train1)[1],28,28,1)
dv<-c(dim(x_valid1)[1],28,28,1)
dt<-c(dim(x_test1)[1],28,28,1)
cb<-list(callback_model_checkpoint(fw1,save_best_only=T),
         callback_reduce_lr_on_plateau(monitor="val_loss",factor=.75))
cnn_fit<-cnnks %>%
    fit(x=array_reshape(x_train1,d),y=cy_train1,
        validation_data=list(array_reshape(x_valid1,dv),cy_valid1),
        shuffle=T,batch_size=128,epochs=30,callbacks=cb)
options(warn=-1,repr.plot.width=11,repr.plot.height=5)
plot(cnn_fit)
load_model_weights_hdf5(cnnks,fw1)
cnnks %>% 
    evaluate(array_reshape(x_test1,dt),cy_test1)

"""<h1 class='font-effect-3d' style='color:#66FF66; font-family:Akronim;'>Regression</h1>
nnet & keras
"""

rnnet<-nnet(x_train2,y_train2,
            size=52,trace=F,maxit=2*10^3,
            linout=T,decay=.1^4)
py_test2<-predict(rnnet,x_test2,type="raw")
options(repr.plot.width=12,repr.plot.height=6)
plot(y_test2,col="#ff9966",type="o",
     xlab='',ylab='',yaxt='n'); par(new=T)
plot(py_test2,col="#66ff66",type="o",
     cex=1.3,ylab='Targets & Predictions')
legend(10,43,legend=c("real","predict"),
       col=c("#ff9966","#66ff66"),lty=c(1,1))
rnnet

mlpks<-keras_model_sequential()
mlpks %>%  
layer_dense(832,input_shape=c(13)) %>%  
layer_activation_leaky_relu(alpha=.025) %>%  
layer_dense(104) %>%  
layer_activation_leaky_relu(alpha=.025) %>%  
layer_dense(1)
mlpks %>%
    compile(loss="mse",optimizer="rmsprop",metrics="mae")
cb<-list(callback_model_checkpoint(fw2,save_best_only=T),
         callback_reduce_lr_on_plateau(monitor="val_loss",factor=.75))
mlp_fit<-mlpks %>%
    fit(x=x_train2,y=y_train2,callbacks=cb,
        validation_data=list(x_valid2,y_valid2),
        shuffle=T,batch_size=24,epochs=300)
load_model_weights_hdf5(mlpks,fw2)
p2y_test2<-predict(mlpks,x_test2,type="raw")
options(repr.plot.width=12,repr.plot.height=6)
plot(y_test2,col="#ff9966",type="o",
     xlab='',ylab='',yaxt='n'); par(new=T)
plot(p2y_test2,col="#66ff66",type="o",
     cex=1.3,ylab='Targets & Predictions')
legend(10,43,legend=c("real","predict"),
       col=c("#ff9966","#66ff66"),lty=c(1,1))
mlpks %>% 
    evaluate(x_test2,y_test2)