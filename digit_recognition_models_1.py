# -*- coding: utf-8 -*-
"""digit-recognition-models-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xoE1CDrpkFYkplH1pJCApKxZjVerYJHg

# Digit Recognition Models #1
### [Colaboratory Version](https://colab.research.google.com/drive/1eqk81yU_y7t6Rridkgli_C7LwPLUFvH2)
"""

import warnings; warnings.filterwarnings('ignore')
import os,pandas as pd,numpy as np,xgboost as xgb
import pylab as pl,seaborn as sn
from scipy import stats
from sklearn import svm,manifold
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.semi_supervised import label_propagation
from sklearn.linear_model import LogisticRegressionCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,hamming_loss
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import RadiusNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier,BernoulliRBM
from keras.utils import to_categorical
pl.style.use('seaborn-whitegrid'); N,N1,N2=5000,7000,6000

def plot_embedding(X,y,title=None):
    x_min,x_max=np.min(X,0),np.max(X,0)
    X=(X-x_min)/(x_max-x_min)
    pl.figure(figsize=(12,10))
    for i in range(X.shape[0]):
        pl.text(X[i,0],X[i,1],str(y[i]),
                 color=pl.cm.Set1(y[i]/10.),
                 fontdict={'weight':'bold','size':10})
    pl.xticks([]),pl.yticks([])
    if title is not None: pl.title(title)
def tts(X,y): 
    x_train,x_test,y_train,y_test=\
    train_test_split(X,y,test_size=.2,random_state=1)
    n=int(len(x_test)/2)
    x_valid,y_valid=x_test[:n],y_test[:n]
    x_test,y_test=x_test[n:],y_test[n:]
    return x_train,x_valid,x_test,y_train,y_valid,y_test
def clf_fit_score(clf,x_train,x_test,y_train,y_test):
    clf.fit(x_train,y_train)    
    y_clf_train=clf.predict(x_train)
    y_clf_test=clf.predict(x_test)        
    acc_clf_train=\
    round(accuracy_score(y_train,y_clf_train),6)
    acc_clf_test=\
    round(accuracy_score(y_test,y_clf_test),6)   
    loss_clf_train=\
    round(hamming_loss(y_train,y_clf_train),6)
    loss_clf_test=\
    round(hamming_loss(y_test,y_clf_test),6)   
    return [str(clf),y_clf_train,y_clf_test,
            acc_clf_train,acc_clf_test,
            loss_clf_train,loss_clf_test]

"""### Data"""

train=pd.read_csv("../input/train.csv")
images=["%s%s" %("pixel",pixel_no) for pixel_no in range(0,784)]
train_images=np.array(train[images])
train_images=train_images.astype('float32')/255
train_images.shape

train_labels=train['label'].values.astype('int16')
train_labels_cat=to_categorical(train_labels,num_classes=10)
train_labels_cat.shape

x_train,x_valid,x_test,\
y_train,y_valid,y_test=tts(train_images,train_labels)

"""### [sklearn.manifold.TSNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)"""

print("Computing t-SNE embedding")
tsne=manifold.TSNE(n_components=2,init='pca',random_state=0)
x_tsne=tsne.fit_transform(train_images[:N])
plot_embedding(x_tsne,train_labels[:N],
               title="t-SNE embedding of digit images")

#!pip install tsnecuda
#from tsnecuda import TSNE
#print("Computing t-SNE embedding")
#x_emb=TSNE(n_components=2).fit_transform(train_images)
#plot_embedding(x_emb,train_labels,
#               title="t-SNE embedding of digit images")

"""### [sklearn.neural_network.MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html/)"""

nn_clf=MLPClassifier(hidden_layer_sizes=(512,),max_iter=80,solver='sgd',
                     verbose=1,random_state=1,learning_rate_init=.01)
nn_clf.fit(x_train,y_train)
[nn_clf.score(x_train,y_train),
 nn_clf.score(x_test,y_test)]

# Commented out IPython magic to ensure Python compatibility.
print("MLPClassifier:\n%s\n"\
# %(classification_report(y_test,nn_clf.predict(x_test))))

"""### [sklearn.neural_network.BernoulliRBM](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html#sklearn.neural_network.BernoulliRBM)"""

x_train_scaled=\
(x_train-np.min(x_train,0))/(np.max(x_train,0)+.0001)
x_test_scaled=\
(x_test-np.min(x_test,0))/(np.max(x_test,0)+.0001)
logistic=LogisticRegression(solver='liblinear',multi_class='ovr',
                            max_iter=50,tol=.0001,C=5000.0)
brbm=BernoulliRBM(random_state=0,verbose=False)
brbm.learning_rate,brbm.n_iter,brbm.n_components=.05,50,64
nn_clf2=Pipeline(steps=[('brbm',brbm),('logistic',logistic)])
nn_clf2.fit(x_train_scaled,y_train)

# Commented out IPython magic to ensure Python compatibility.
print("Logistic regression & BRBM features:\n%s\n"\
# %(classification_report(y_test,nn_clf2.predict(x_test_scaled))))

"""### [sklearn ensemble methods](https://scikit-learn.org/stable/modules/ensemble.html) & other classifiers"""

clf=[svm.SVC(C=10.0,kernel='poly'),
     xgb.XGBClassifier(objective="multi:softprob",random_state=42)]
#     LogisticRegressionCV(solver='liblinear',multi_class='ovr'),
#     KNeighborsClassifier(),
#     RadiusNeighborsClassifier(radius=30),
#     RandomForestClassifier(n_estimators=64,max_depth=11)]

result=[]
for c in clf:
    result.append(clf_fit_score(c,x_train[:N1],x_test[:N1-N2],
                                y_train[:N1],y_test[:N1-N2]))

for i in range(2):
    print(result[i][0])
    print('accuracy train/test: %s'%result[i][3:5])
    print('loss train/test: %s'%result[i][5:7])
    print(50*'=')

"""### [sklearn.semi_supervised.LabelSpreading](http://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelSpreading.html#sklearn.semi_supervised.LabelSpreading)"""

n_total=N1; n_labeled=N2
X=np.copy(train_images[:n_total])
y=np.copy(train_labels[:n_total])
y[n_labeled:]=-1
lp_model=label_propagation\
.LabelSpreading(kernel='knn',n_neighbors=10,
                n_jobs=-1,max_iter=200)
lp_model.fit(X,y)
pred_labels=lp_model.transduction_[n_labeled:n_total]
true_labels=train_labels[n_labeled:n_total]

print("Label Spreading: %d labeled & %d unlabeled points (%d total)"%\
      (n_labeled,n_total-n_labeled,n_total))
print(classification_report(true_labels,pred_labels))
print("Confusion matrix")
confusionmatrix=confusion_matrix(true_labels,pred_labels,
                                 labels=lp_model.classes_)
print(confusionmatrix)

predict_entropies=stats.distributions\
.entropy(lp_model.label_distributions_.T)
uncertainty_index=np.argsort(predict_entropies)[-10:]
ui=pl.figure(figsize=(10,5))
for index,image_index in enumerate(uncertainty_index):
    image=train_images[image_index].reshape(28,28)
    sub=ui.add_subplot(2,5,index+1)
    sub.imshow(image,cmap=pl.cm.bone)
    pl.xticks([]); pl.yticks([])
    sub.set_title('predict: %i\ntrue: %i'%(
        lp_model.transduction_[image_index],
        train_labels[image_index]))